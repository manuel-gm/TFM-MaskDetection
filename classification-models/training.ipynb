{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM5wrJwu4XaStyDB/L8b0Vv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cfgQIe91Y4or"},"source":["Este cuaderno de Jypiter sirve para entrenar el modelo clasificador MobileNet v2.\n","\n","Basado en este [cuaderno](https://github.com/aryan109/medium/blob/master/Custom_Image_Classification/Custom_image_clasification.ipynb)."]},{"cell_type":"markdown","metadata":{"id":"TBeJykXkY2j7"},"source":["# Montar el Drive"]},{"cell_type":"code","metadata":{"id":"BhSYcuQvjonD"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TW_J46Fwj-Rl"},"source":["import os\n","os.chdir('/content/gdrive/My Drive/TFM-MaskDetection/classification-models/') # Cambia al directorio donde se encuentra training.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qf7kbNdKWpHc"},"source":["# Crear el dataset de entrenamiento\n","\n"]},{"cell_type":"code","metadata":{"id":"VYC9mOu0WoW8"},"source":["import cv2 as cv2\n","import matplotlib.pyplot as plt\n","from pandas import read_csv\n","\n","# Path declaration\n","IMAGES_PATH = r\"./images/\"\n","DATASET_PATH = r\"./dataset/\"\n","TRAINING_DATASET_PATH = DATASET_PATH + r\"train/\"\n","EVAL_DATASET_PATH = DATASET_PATH + r\"eval/\"\n","# Training sub-dataset\n","paths = [[\"images/train_labels.csv\",IMAGES_PATH+\"train/\",DATASET_PATH],\n","         [\"images/test_labels.csv\", IMAGES_PATH+\"test/\", DATASET_PATH]]\n","       \n","k = 0\n","for i, path in enumerate(paths):\n","    print(path, path[0], path[1], path[2])\n","    labels = read_csv(path[0])  # labels.csv file\n","    src_img_path = path[1]      # source image path\n","    dst_img_path = path[2]      # destination dataset path\n","    \n","    for row in labels.iloc:\n","        # Extract dataset\n","        img_name = row.filename # Image filename with extension\n","        img_id = img_name[:-4]  # Image id (name without extension)\n","        img_class = row.Class   # Object class\n","        \n","        # Read image and segment\n","        img_src = cv.imread(src_img_path + img_name)\n","        img_segm = img_src[row.ymin:row.ymax, row.xmin:row.xmax]\n","        img_segm = cv.resize(img_segm, (224, 224))\n","        \n","        # Save new image\n","        path = dst_img_path + img_class + '/' + str(k) + '.png'\n","        cv.imwrite(path, img_segm)\n","        \n","        k += 1\n","    \n","    print(\"Imagenes guardadas en \" + path[2])\n","print(\"Terminado!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1uW_5vhzBpwf"},"source":["# Entrenamiento"]},{"cell_type":"code","metadata":{"id":"KhB_EAgx8Y7D"},"source":["try:\n","  # The %tensorflow_version magic only works in colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","pd.set_option(\"display.precision\", 8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAPmy17MEk0F"},"source":["TRAINING_DATA_DIR = r\"./dataset\"\n","MODEL_NAME = 'mobilenet_v2'\n","EPOCHS = 100\n","SAVED_PATH = os.path.join(\"saved_models\", MODEL_NAME, str(EPOCHS))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kN6LuFifE6Ax"},"source":["Carga del dataset y del modelo"]},{"cell_type":"code","metadata":{"id":"7OHniaQw86qM"},"source":["datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n","valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n","valid_generator = valid_datagen.flow_from_directory(\n","    TRAINING_DATA_DIR, \n","    subset=\"validation\", \n","    shuffle=True,\n","    target_size=(224,224)\n",")\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n","train_generator = train_datagen.flow_from_directory(\n","    TRAINING_DATA_DIR, \n","    subset=\"training\", \n","    shuffle=True,\n","    target_size=(224,224)\n",")\n","\n","for image_batch, label_batch in train_generator:\n","  break\n","print(image_batch.shape, label_batch.shape)\n","\n","print(train_generator.class_indices)\n","labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n","with open('labels.txt', 'w') as f:\n","  f.write(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGt3P7xD_bsP"},"source":["model = tf.keras.Sequential([\n","  hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n","                output_shape=[1280],\n","                trainable=False),\n","  tf.keras.layers.Dropout(0.4),\n","  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n","])\n","\n","model.build([None, 224, 224, 3])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0POwMi9Bcnk"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","model.compile(\n","  optimizer=optimizer,\n","  loss='categorical_crossentropy',\n","  metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-iZ9-eqOF5Yc"},"source":["Entrenamiento"]},{"cell_type":"code","metadata":{"id":"_TZaA8RjBnMJ"},"source":["steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n","val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n","\n","hist = model.fit(\n","    train_generator, \n","    epochs=EPOCHS,\n","    verbose=1,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=valid_generator,\n","    validation_steps=val_steps_per_epoch).history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MU6QYqOoD_KM"},"source":["Evaluación del entrenamiento"]},{"cell_type":"code","metadata":{"id":"dh2YwKspDvH7"},"source":["final_loss, final_accuracy = model.evaluate(valid_generator, steps = val_steps_per_epoch)\n","print(\"Final loss: {:.2f}\".format(final_loss))\n","print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deFlY0-ED-af"},"source":["plt.figure()\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,50])\n","plt.plot(hist[\"loss\"])\n","plt.plot(hist[\"val_loss\"])\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,1])\n","plt.plot(hist[\"acc\"])\n","plt.plot(hist[\"val_acc\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yLYiG9l3EW-a"},"source":["Guardado del modelo"]},{"cell_type":"code","metadata":{"id":"IGLQPs16EaYb"},"source":["model.save(SAVED_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dj2qDpD5EUlP"},"source":["Test de predicción"]},{"cell_type":"code","metadata":{"id":"nuQDkWgzpRIR"},"source":["model = tf.keras.models.load_model(SAVED_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryodUMmjHoGs"},"source":["val_image_batch, val_label_batch = next(iter(valid_generator))\n","true_label_ids = np.argmax(val_label_batch, axis=-1)\n","print(\"Validation batch shape:\", val_image_batch.shape)\n","print(val_image_batch.dtype)\n","\n","dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n","dataset_labels = np.array([key.title() for key, value in dataset_labels])\n","print(dataset_labels)\n","\n","tf_model_predictions = model.predict(val_image_batch)\n","print(\"Prediction results shape:\", tf_model_predictions.shape)\n","\n","predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n","predicted_labels = dataset_labels[predicted_ids]\n","print(predicted_labels)\n","\n","plt.figure(figsize=(10,9))\n","plt.subplots_adjust(hspace=0.5)\n","for n in range((len(predicted_labels)-2)):\n","  plt.subplot(6,5,n+1)\n","  plt.imshow(val_image_batch[n])\n","  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n","  plt.title(predicted_labels[n].title(), color=color)\n","  plt.axis('off')\n","_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\n"],"execution_count":null,"outputs":[]}]}