{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":["urD8xmu8PUrs","c3wuEMfIPaVt"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3b8MHmzV7M0I"},"source":["Este cuaderno de Jypiter se ha elaborado para entrenar modelos de detección utilizando TensorFlow 2 Object Detection API.\n","Los modelos deben ser descargados desde el [model zoo de la API](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). La evaluación de los modelos se realiza con el script de [Padilla et al.](https://github.com/rafaelpadilla/Object-Detection-Metrics)\n","\n","El entrenamiento está basado en el tutorial de [Renu Khandelwal](https://medium.com/analytics-vidhya/tensorflow-2-object-detection-api-using-custom-dataset-745f30278446)."]},{"cell_type":"markdown","metadata":{"id":"urD8xmu8PUrs"},"source":["# Montar el Drive"]},{"cell_type":"code","metadata":{"id":"BhSYcuQvjonD"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TW_J46Fwj-Rl"},"source":["import os\n","os.chdir('/content/gdrive/My Drive/TFM-MaskDetection/detecion-models/') # Cambia al directorio donde se encuentra training.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3wuEMfIPaVt"},"source":["# Instalación de TensorFlow 2 Object Detection API"]},{"cell_type":"code","metadata":{"id":"Gs__Df3EPetD"},"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZA2UdN2Ygc7Q"},"source":["%%bash\n","cd models/research\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yoYx0VatQoh0"},"source":["# Clone the pycocotools API repository if it doesn't already exist\n","if \"cocoapi\" in pathlib.Path.cwd().parts:\n","  while \"cocoapi\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('cocoapi').exists():\n","  !git clone --depth 1 https://github.com/cocodataset/cocoapi.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XEwnF4KfSMGs"},"source":["#Preparación del dataset"]},{"cell_type":"code","metadata":{"id":"3PG7nK-KhsF3"},"source":["## Comprueba que todas las imagenes son correctas\n","from skimage import io\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","\n","mypaths = ['Workspace/images/train/', 'Workspace/images/test/']\n","for mypath in mypaths:\n","\n","  files = [mypath+f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith(\".png\"))]\n","  for i in range(len(files)):   \n","    try:\n","        _ = io.imread(files[i])\n","        img = cv2.imread(files[i])\n","    except Exception as e:\n","        print(e)\n","        print(files[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYTMsHCSUn3Z"},"source":["# Crea el fichero csv a partir de los xml\n","!python xml_to_csv.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slaSsCGNV2GP"},"source":["# Crea los tfrecords a partir de los csv\n","!python generate_tfrecord.py --csv_input=Workspace/images/train_labels.csv --image_dir=Workspace/images/train --output_path=train.record\n","!python generate_tfrecord.py --csv_input=Workspace/images/test_labels.csv --image_dir=Workspace/images/test --output_path=test.record"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhOVHoep-s_T"},"source":["## Creación de ficheros .txt con las Ground Truth que se utilizará durante la evaluación del modelo para calcular las métricas de error"]},{"cell_type":"code","metadata":{"id":"FhC1rOliJaqP"},"source":["# Ground truth\n","import csv\n","import glob\n","\n","GROUND_TRUTH_PATH = 'Evaluation/ground_truth/'\n","\n","# Delete all previous files\n","files = glob.glob(GROUND_TRUTH_PATH + '*')\n","for f in files:\n","    os.remove(f)\n","print(\"Previous files were deleted\")\n","\n","with open('Workspace/images/test_labels.csv', 'r') as src:\n","  csv_reader = csv.reader(src, delimiter=',')\n","  line_count = 0\n","  img_name_prev = ''\n","  img_name = ''\n","  dst = open(GROUND_TRUTH_PATH+img_name+'.txt', 'a')\n","  for row in csv_reader:\n","      if line_count == 0:\n","          line_count += 1\n","      else:\n","          img_name = row[0][:-4]\n","          if img_name != img_name_prev:\n","              dst.close()\n","              dst = open(GROUND_TRUTH_PATH+img_name+'.txt', 'a')\n","          img_name_prev = img_name\n","          buffer = ''\n","          if row[3] == 'without_mask':\n","            buffer += '1 '\n","          elif row[3] == 'with_mask':\n","            buffer += '2 '\n","          elif row[3] == 'mask_weared_incorrect':\n","            buffer += '3 '\n","          buffer += row[4] + ' ' + row[5] + ' ' + row[6] + ' ' + row[7] + '\\n'\n","          dst.write(buffer)\n","          line_count += 1\n","  dst.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jP_VmSFCbSiy"},"source":["# Entrenamiento del modelo"]},{"cell_type":"markdown","metadata":{"id":"3yvE18_e9RT6"},"source":["A partir de aquí será necesario modificar el nombre del modelo en función del que se desee entrenar. Se indicará los lugares en los que es necesario aplicar el cambio."]},{"cell_type":"code","metadata":{"id":"V-E3_h--bV2M"},"source":["!python Workspace/model_main_tf2.py \\\n","     --model_dir=Workspace/models/<__MODEL_NAME__> \\\n","     --pipeline_config_path=Workspace/models/<__MODEL_NAME__>/pipeline.config"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9I3Vb1fDV7m"},"source":["## Exportación"]},{"cell_type":"code","metadata":{"id":"Z4FrhtKhDah7"},"source":["!python Workspace/exporter_main_v2.py \\\n","        --input_type=image_tensor \\\n","        --trained_checkpoint_dir=Workspace/models/<__MODEL_NAME__> \\\n","        --pipeline_config_path=Workspace/models/<__MODEL_NAME__>/pipeline.config \\\n","        --output_directory=Workspace/exported_model/<__MODEL_NAME__>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAIXpw4i-jmv"},"source":["# Evaluación"]},{"cell_type":"code","metadata":{"id":"34wmTsUd-i52"},"source":["# Descarga del software para calcular las métricas\n","!git clone --depth 1 https://github.com/rafaelpadilla/Object-Detection-Metrics.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiwJiejCNgFB"},"source":["# Evaluación: se calculan las bounding boxes del dataset de evaluación y se\n","# guardan en un fichero .txt que se utilizará para calcular las métricas\n","\n","# Import the required libraries for Object detection infernece\n","import time\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import glob\n","%matplotlib inline\n","\n","#Loading the exported model from saved_model directory\n","MODEL = '<__MODEL_NAME__>'\n","PATH_TO_SAVED_MODEL =r'Workspace/exported_model/' + MODEL + '/saved_model'\n","BBOX_PATH = \"Evaluation/detection_bbox/\"\n","# Delete previous files\n","files = glob.glob(BBOX_PATH + MODEL + '/*')\n","for f in files:\n","    os.remove(f)\n","print(\"Previous files were deleted\")\n","\n","# setting min confidence threshold\n","MIN_CONF_THRESH=0.5\n","print('Loading model...', end='')\n","start_time = time.time()\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n","# LOAD LABEL MAP DATA\n","PATH_TO_LABELS=r'Workspace/annotations/label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","    Puts image into numpy array of shape (height, width, channels), where channels=3 for RGB to feed into tensorflow graph.\n","    Args:\n","      path: the file path to the image\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB))\n","\n","#Image file for inference\n","IMAGE_FOLDER=r'Workspace/images/test/*.png'\n","i = 0\n","for IMAGE_PATH in glob.glob(IMAGE_FOLDER):\n","    image_np = load_image_into_numpy_array(IMAGE_PATH)\n","    # Running the infernce on the image specified in the  image path\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","    #print(detections['detection_classes'])\n","    image_np_with_detections = image_np.copy()\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=MIN_CONF_THRESH,\n","          agnostic_mode=False)\n","    \n","    # Save into .txt\n","    height, width, _ = image_np_with_detections.shape\n","    with open(BBOX_PATH+MODEL+IMAGE_PATH[21:-4]+'.txt', 'a') as textfile:\n","        for n,_ in enumerate(detections['detection_classes']):\n","            buffer = str(detections['detection_classes'][n])  + \" \" + \\\n","                     str(detections['detection_scores'][n])   + \" \" + \\\n","                     str(detections['detection_boxes'][n][1]*width) + \" \" + \\\n","                     str(detections['detection_boxes'][n][0]*height)  + \" \" + \\\n","                     str(detections['detection_boxes'][n][3]*width) + \" \" + \\\n","                     str(detections['detection_boxes'][n][2]*height)  + \"\\n\"\n","            textfile.write(buffer)\n","    if (i%10 == 0):\n","        print(\"{:.2f}% done\".format(100*i/169))\n","    i = i+1\n","\n","print('100.00% done')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIQU59P2ffka"},"source":["# Cálculo de las métricas de error\n","# Requiere crear un directorio ./metrics/<__MODEL_NAME__>\n","\n","os.chdir('Object-Detection-Metrics/')\n","!python3 pascalvoc.py -gt ../Evaluation/ground_truth/ \\                         # Directorio con las ground truth\n","      -det ../Evaluation/detection_bbox/<__MODEL_NAME__>/ \\                     # Directorio con las bounding boxes\n","      -t 0.5 \\                                                                  # Threshold\n","      -sp ../Evaluation/metrics/<__MODEL_NAME__>/                               # Directorio de salida\n","os.chdir('..')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"htu6HwkmNdBw"},"source":["#Inferencia"]},{"cell_type":"markdown","metadata":{"id":"nCbNipxR_x6_"},"source":["A continuación se dejan dos scripts para realizar la inferencia tanto de imágenes como de vídeo. El resultado se almacena en la carpeta especificada."]},{"cell_type":"code","metadata":{"id":"FA9im1nXbndR"},"source":["# Image input\n","!python Workspace/detect_objects.py --threshold=0.5 \\                           # Threshold\n","      --model_path=Workspace/exported_model/<__MODEL_NAME__>/saved_model \\      # Modelo empleado\n","      --path_to_labelmap=Workspace/annotations/label_map.pbtxt \\\n","      --images_dir=Test/src/images \\                                            # Directorio con las imágenes de entrada\n","      --output_directory=Test/dst/<__MODEL_NAME__> \\                            # Directorio con las imágenes de salida\n","      --save_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJYtKP9c_SE4"},"source":["# Video input\n","!python Workspace/detect_objects.py --video_input --threshold=0.5 \\             # Threshold\n","      --model_path=Workspace/exported_model/<__MODEL_NAME__>/saved_model \\      # Modelo empleado\n","      --path_to_labelmap=Workspace/annotations/label_map.pbtxt \\                \n","      --video_path=Test/src/video.mp4 \\                                         # Video de entrada\n","      --output_directory=Test/dst/<__MODEL_NAME__> \\                            # Directorio de salida\n","      --save_output"],"execution_count":null,"outputs":[]}]}